{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/czephyr/AMD_project/blob/main/colab_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.3.2/spark-3.3.2-bin-hadoop3.tgz\n",
        "!tar xf spark-3.3.2-bin-hadoop3.tgz"
      ],
      "metadata": {
        "id": "HiKF0k5uEfJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.2-bin-hadoop3\""
      ],
      "metadata": {
        "id": "gGuGBQoSEr0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q findspark\n",
        "!pip install -q pyspark\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "IkF2vSXIDWnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRnhMrXxCuw0"
      },
      "outputs": [],
      "source": [
        "os.environ['KAGGLE_USERNAME'] = \"xxxxxxxxxx\"\n",
        "os.environ['KAGGLE_KEY'] = \"xxxxxxxxxxxxxxx\"\n",
        "!kaggle datasets download -f amazon_reviews_us_Baby_v1_00.tsv cynthiarempel/amazon-us-customer-reviews-dataset\n",
        "!kaggle datasets download -f amazon_reviews_us_Digital_Music_Purchase_v1_00.tsv cynthiarempel/amazon-us-customer-reviews-dataset\n",
        "!kaggle datasets download -f amazon_reviews_us_Digital_Video_Games_v1_00.tsv cynthiarempel/amazon-us-customer-reviews-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pXcdJPACb98"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"amazon_reviews_us_Baby_v1_00.tsv.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\".\")\n",
        "with zipfile.ZipFile(\"amazon_reviews_us_Digital_Music_Purchase_v1_00.tsv.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\".\")\n",
        "with zipfile.ZipFile(\"amazon_reviews_us_Digital_Video_Games_v1_00.tsv.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\".\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZ9LaOaWCuw2"
      },
      "source": [
        "### Data to adjacency list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6r4rhHRgCuw3"
      },
      "outputs": [],
      "source": [
        "# the dataset is composed by Baby items, Digital Music and Digital Videogames\n",
        "# RDD (customer,product)\n",
        "tsv0 = spark.read.option(\"header\", \"true\").option(\"sep\", \"\\t\").csv(\"amazon_reviews_us_Baby_v1_00.tsv\").select([\"customer_id\",\"product_parent\"]).rdd\n",
        "tsv1 = spark.read.option(\"header\", \"true\").option(\"sep\", \"\\t\").csv(\"amazon_reviews_us_Digital_Music_Purchase_v1_00.tsv\").select([\"customer_id\",\"product_parent\"]).rdd\n",
        "tsv2 = spark.read.option(\"header\", \"true\").option(\"sep\", \"\\t\").csv(\"amazon_reviews_us_Digital_Video_Games_v1_00.tsv\").select([\"customer_id\",\"product_parent\"]).rdd\n",
        "tsv = tsv0.union(tsv1).union(tsv2)\n",
        "data = tsv\n",
        "print(f\"Rows in the dataset: {data.count()}\")\n",
        "data.take(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfJIYLgyCuw5"
      },
      "outputs": [],
      "source": [
        "data.take(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFQIgUTLCuw6"
      },
      "outputs": [],
      "source": [
        "# Extract id of Digital Videogames products in the database\n",
        "video_games = tsv2.map(lambda x: x[1]).distinct()\n",
        "video_games.take(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4wJAE0jCuw7"
      },
      "outputs": [],
      "source": [
        "# Extract id of Baby products in the database\n",
        "baby = tsv0.map(lambda x: x[1]).distinct()\n",
        "baby.take(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9xXpb1yCuw8"
      },
      "outputs": [],
      "source": [
        "# Extract id of Digital Music products in the database\n",
        "music = tsv1.map(lambda x: x[1]).distinct()\n",
        "music.take(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBUhtCMuCuw8"
      },
      "outputs": [],
      "source": [
        "#### CELL 5\n",
        "# Create couples of items purchased by the same customer\n",
        "# RDD [(customer1, (product1,product2)),(customer2, (product3,product4)),(...)]\n",
        "data_joined = data.join(data)\n",
        "data_joined.take(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fG63_B9wCuw9"
      },
      "outputs": [],
      "source": [
        "#### CELL 6\n",
        "# Remove duplicate item couples created by the join\n",
        "# RDD [(customer1, (product1,product2)),(customer2, (product3,product4)),(...)]\n",
        "data_filtered = data_joined.filter(lambda x : x[1][0]!= x[1][1])\n",
        "data_filtered.take(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sOMBHcrCuw-"
      },
      "outputs": [],
      "source": [
        "#### CELL 7\n",
        "# Create list of links between products\n",
        "# RDD [(product1,product2),(product3,product4),(...))]\n",
        "edge_list = data_filtered.map(lambda x : x[1])\n",
        "edge_list.take(2) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3EuPTDnCuw_"
      },
      "outputs": [],
      "source": [
        "#### CELL 8\n",
        "# Make second item a list\n",
        "# RDD [(node1, [node2]),(node1, [node2]),(...)]\n",
        "adjacency1 = edge_list.mapValues(lambda v: [v])\n",
        "\n",
        "# RDD [(node1,[node2,node3,...]),(...)]\n",
        "adjacency_list = adjacency1.reduceByKey(lambda a,b: a + b)\n",
        "\n",
        "adjacency_list.take(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ynfaz6uECuxA"
      },
      "source": [
        "### Calculate pagerank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eyglSkxCuxA"
      },
      "outputs": [],
      "source": [
        "#### CELL 9\n",
        "def calculate_initial_contribs(row):\n",
        "    \"\"\"\n",
        "    This function takes elements from the joined dataset above and\n",
        "    computes the contribution to each outgoing link based on the\n",
        "    current rank.\n",
        "    \"\"\"\n",
        "    item, array = row\n",
        "    num_edges = len(array)\n",
        "    for node in array:\n",
        "        yield item, node, 1/num_edges\n",
        "\n",
        "# transition matrix stored as triplets\n",
        "# RDD [(product1,(product2,probability)),(product3,(product4,probability))]\n",
        "trans_matrix = adjacency_list.flatMap(calculate_initial_contribs).cache()\n",
        "trans_matrix.take(10) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pH-3byHpCuxA"
      },
      "outputs": [],
      "source": [
        "# Product names\n",
        "keys = trans_matrix.map(lambda x : x[0]).distinct().collect()\n",
        "# map product names to integers\n",
        "indexmap = dict(zip(keys, range(len(keys))))\n",
        "\n",
        "# map items to indexes\n",
        "# RDD [(index_product1,(index_product2,probability)),(index_product3,(index_product4,probability))]\n",
        "hashed_matrix = trans_matrix.map(lambda x: (indexmap[x[0]],(indexmap[x[1]],x[2])))\n",
        "hashed_matrix.take(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WYlz3CNCuxB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Array of pagerank stored in memory\n",
        "n = len(keys) # num of products in adjacency list\n",
        "pgrnk = np.ones(n)/n # time t\n",
        "previus_pgrnk = np.ones(n) # time -1\n",
        "     \n",
        "# MSE distance between previous pgrank iteration\n",
        "def l2distance(v, q):   \n",
        "    return sum([(q_el - v_el)**2 for v_el, q_el in zip(v, q)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeqmmILbCuxB"
      },
      "outputs": [],
      "source": [
        "#### CELL 15\n",
        "tolerance = 10e-10\n",
        "max_iterations = 300\n",
        "i = 0\n",
        "tax = 0.85\n",
        "\n",
        "while(l2distance(previus_pgrnk, pgrnk) >= tolerance and i < max_iterations):\n",
        "    previus_pgrnk = np.copy(pgrnk)\n",
        "\n",
        "    page_rank_values = (hashed_matrix\n",
        "                    .mapValues(lambda v: tax*(v[1]*pgrnk[v[0]]) + (1-tax)*(1/n)) \n",
        "                    .reduceByKey(lambda a, b: a+b)\n",
        "                    .sortByKey()\n",
        "                    .collect()\n",
        "                    )\n",
        "  \n",
        "    pgrnk = np.array([c for (i, c) in page_rank_values])\n",
        "    i=i+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43oG3GYpCuxB"
      },
      "outputs": [],
      "source": [
        "# Avg pagerank\n",
        "np.mean(pgrnk)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9P6wXv7CuxD"
      },
      "source": [
        "### Topic aware page rank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxLQhQBrCuxD"
      },
      "outputs": [],
      "source": [
        "vgdict = video_games.collect()\n",
        "vg_array = [1 if (x in vgdict) else 0 for x in indexmap]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_EgRToRCuxD"
      },
      "outputs": [],
      "source": [
        "# Reset arrays\n",
        "n = len(keys) # num of products in adjacency list\n",
        "pgrnk = np.ones(n)/n # time t\n",
        "previus_pgrnk = np.ones(n) # time -1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ekqa6CHyCuxD"
      },
      "outputs": [],
      "source": [
        "#### CELL 18\n",
        "tolerance = 10e-10\n",
        "max_iterations = 300\n",
        "i = 0\n",
        "tax = 0.85\n",
        "\n",
        "# size of the page in the topic set\n",
        "len_topic = video_games.count()    \n",
        "\n",
        "# if the page is in the selected topic set it's pgrank calculation will have\n",
        "# the added weight from the teletrasportation\n",
        "def calcPgRnk(row):\n",
        "    return tax*(row[1]*pgrnk[row[0]]) + vg_array[row[0]]*(1-tax)*(1/len_topic)\n",
        "\n",
        "\n",
        "while(l2distance(previus_pgrnk, pgrnk) >= tolerance or i < max_iterations):\n",
        "  \n",
        "    previus_pgrnk = np.copy(pgrnk) \n",
        "    page_rank_values = (hashed_matrix\n",
        "                        .mapValues(calcPgRnk) \n",
        "                        .reduceByKey(lambda a, b: a+b) \n",
        "                        .sortByKey()\n",
        "                        .collect()\n",
        "                       )\n",
        "  \n",
        "    pgrnk = np.array([c for (i, c) in page_rank_values])\n",
        "    i = i + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NspPg78mCuxE"
      },
      "outputs": [],
      "source": [
        "# Avg pgrnk for videogame products\n",
        "sum = 0\n",
        "for pg,vg in zip(pgrnk,vg_array):\n",
        "    sum = pg*vg + sum \n",
        "\n",
        "sum/len_topic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgO-fu5JCuxE"
      },
      "outputs": [],
      "source": [
        "# Avg pgrnk for products in the other two categories\n",
        "sum_others = 0\n",
        "for pg,vg in zip(pgrnk,vg_array):\n",
        "    sum_others = pg*int(not(vg)) + sum_others\n",
        "\n",
        "sum_others / (len(pgrnk)-len_topic)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "malchiodi-MymJiiy4",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}